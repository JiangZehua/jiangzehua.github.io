<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Zehua Jiang </title> <meta name="author" content="Zehua Jiang"> <meta name="description" content="PhD student in Computer Science at New York University. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/lvesuotu.JPG?143dbb683976f8e263f898a9041f7a50"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jiangzehua.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/posts/index.html">Posts </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Zehua Jiang </h1> <p class="desc"><a href="https://www.nyu.edu/" rel="external nofollow noopener" target="_blank">New York University</a>. zehua.jiang@nyu.edu</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?d03e87b37ececc0ac83237f2d05eeb1b" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Hi! I’m Zehua Jiang!</p> <p>I am currently pursuing my PhD in Computer Science at New York University. Prior to this, I earned my Master’s degree in Electrical and Computer Engineering at NYU and a Bachelor’s degree from the School of Physics at <a href="https://www.sysu.edu.cn/sysuen/" rel="external nofollow noopener" target="_blank">Sun Yat-sen University</a>. I am a researcher, programmer, traveler, photographer, and video editor.</p> <p>My research journey at the <a href="https://game.engineering.nyu.edu/" rel="external nofollow noopener" target="_blank">NYU Game Innovation Lab</a> with Prof. <a href="http://julian.togelius.com/" rel="external nofollow noopener" target="_blank">Julian Togelius</a> has been marked by contributions to a range of stimulating projects. My work primarily focuses on procedural content generation (PCG) in games and generating synthetic biometric information (including iris and fingerprint data).</p> <p>My contact information is listed in the icons below, feel free to contact me anytime!</p> <hr> <p>My name is typically pronounced as “Ze-hua Jiang” in English. Here’s a rough breakdown of the pronunciation:</p> <ul> <li>“Ze” is pronounced like “<em>zuh</em>” with a soft “z” sound and a slight “uh” sound at the end.</li> <li>“hua” is pronounced like “<em>hwa</em>”, with a soft “h” sound and a slight “w” sound at the beginning.</li> <li>“Jiang” is pronounced like “<em>jahng</em>”, with a soft “j” sound at the beginning and a nasal “ng” sound at the end.</li> </ul> <hr> <p>你好！我是蒋泽华！</p> <p>我是纽约大学计算机科学专业的博士研究生。此前我在纽约大学完成了电子与计算机工程专业的硕士学位，以及在<a href="https://www.sysu.edu.cn/sysuen/" rel="external nofollow noopener" target="_blank">中山大学</a>光电信息科学与工程专业获得学士学位。我是一名研究者、程序员、旅行者、摄影师和视频剪辑师。作为<a href="https://game.engineering.nyu.edu/" rel="external nofollow noopener" target="_blank">纽约大学游戏创新实验室</a>的一员，在<a href="http://julian.togelius.com/" rel="external nofollow noopener" target="_blank">Julian Togelius</a>教授的指导下，我参与的项目包括游戏中程序内容生成（PCG）的研究，以及生物特征信息（包括虹膜和指纹数据）的合成。我的联系方式列在了下方的图标中，欢迎随时与我联系！</p> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jan 08, 2024</th> <td> Passed my qualifying exam! </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 13, 2023</th> <td> Became a co-organizer of <a href="https://aingames.cn/ieee-wcci24-games/" rel="external nofollow noopener" target="_blank">Special Session on Games</a> at <a href="https://2024.ieeewcci.org/" rel="external nofollow noopener" target="_blank">WCCI/CEC2024</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 22, 2023</th> <td> Finished the first tutorial session “Controllable Content Generators via Reinforcement Learning” with <a href="https://twitter.com/Smearle_RH" rel="external nofollow noopener" target="_blank">Sam Earle</a> in <a href="https://2023.ieee-cog.org/program/" rel="external nofollow noopener" target="_blank">IEEE CoG 2023</a> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="jiang2022learning" class="col-sm-8"> <div class="title">Learning Controllable 3D Level Generators</div> <div class="author"> <strong>Zehua Jiang</strong> ,  Sam Earle ,  Michael Green ,  and  Julian Togelius </div> <div class="periodical"> <em>In Proceedings of the 17th International Conference on the Foundations of Digital Games</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/abs/10.1145/3555858.3563273" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Procedural Content Generation via Reinforcement Learning (PCGRL) foregoes the need for large human-authored data-sets and allows agents to train explicitly on functional constraints, using computable, user-defined measures of quality instead of target output. We explore the application of PCGRL to 3D domains, in which content-generation tasks naturally have greater complexity and potential pertinence to real-world applications. Here, we introduce several PCGRL tasks for the 3D domain, Minecraft. These tasks will challenge RL-based generators using affordances often found in 3D environments, such as jumping, multiple dimensional movement, and gravity. We train agents to optimize each of these tasks to explore the capabilities of existing in PCGRL. The agents are able to generate relatively complex and diverse levels, and generalize to random initial states and control targets. Controllability tests in the presented tasks demonstrate their utility to analyze success and failure for 3D generators. We argue that these generators could serve both as co-creative tools for game designers, and as pre-trained environment generators in curriculum learning for player agents.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">jiang2022learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Controllable 3D Level Generators}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jiang, Zehua and Earle, Sam and Green, Michael and Togelius, Julian}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 17th International Conference on the Foundations of Digital Games}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--9}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="charity2022diversity" class="col-sm-8"> <div class="title">Diversity and Novelty MasterPrints: Generating Multiple DeepMasterPrints for Increased User Coverage</div> <div class="author"> M Charity ,  Nasir Memon ,  <strong>Zehua Jiang</strong> ,  Abhi Sen ,  and  Julian Togelius </div> <div class="periodical"> <em>In 2022 International Conference of the Biometrics Special Interest Group (BIOSIG)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/9897028" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This work expands on previous advancements in genetic fingerprint spoofing via the DeepMasterPrints and introduces Diversity and Novelty MasterPrints. This system uses quality diversity evolutionary algorithms to generate dictionaries of artificial prints with a focus on increasing coverage of users from the dataset. The Diversity MasterPrints focus on generating solution prints that match with users not covered by previously found prints, and the Novelty MasterPrints explicitly search for prints with more that are farther in user space than previous prints. Our multi-print search methodologies outperform the singular DeepMasterPrints in both coverage and generalization while maintaining quality of the fingerprint image output.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">charity2022diversity</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diversity and Novelty MasterPrints: Generating Multiple DeepMasterPrints for Increased User Coverage}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Charity, M and Memon, Nasir and Jiang, Zehua and Sen, Abhi and Togelius, Julian}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 International Conference of the Biometrics Special Interest Group (BIOSIG)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--4}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Banerjee_2024_WACV" class="col-sm-8"> <div class="title">Alpha-Wolves and Alpha-Mammals: Exploring Dictionary Attacks on Iris Recognition Systems</div> <div class="author"> Sudipta Banerjee ,  Anubhav Jain ,  <strong>Zehua Jiang</strong> ,  Nasir Memon ,  Julian Togelius ,  and  Arun Ross </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops</em> , Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/WACV2024W/MAP-A/html/Banerjee_Alpha-Wolves_and_Alpha-Mammals_Exploring_Dictionary_Attacks_on_Iris_Recognition_Systems_WACVW_2024_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>A dictionary attack in a biometric system entails the use of a small number of strategically generated images or templates to successfully match with a large number of identities, thereby compromising security. We focus on dictionary attacks at the template level, specifically the IrisCodes used in iris recognition systems. We present an hitherto unknown vulnerability wherein we mix IrisCodes using simple bitwise operators to generate alpha-mixtures— alpha-wolves (combining a set of "wolf" samples) and alpha-mammals (combining a set of users selected via search optimization) that increase false matches. We evaluate this vulnerability using the IITD, CASIA-IrisV4-Thousand and Synthetic datasets, and observe that an alpha-wolf (from two wolves) can match upto 71 identities @FMR=0.001%, while an alpha-mammal (from two identities) can match upto 133 other identities @FMR=0.01% on the IITD dataset. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Banerjee_2024_WACV</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Banerjee, Sudipta and Jain, Anubhav and Jiang, Zehua and Memon, Nasir and Togelius, Julian and Ross, Arun}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Alpha-Wolves and Alpha-Mammals: Exploring Dictionary Attacks on Iris Recognition Systems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1072-1081}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%7A%65%68%75%61.%6A%69%61%6E%67@%6E%79%75.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-1807-7826" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=N6yADnMAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/JiangZehua" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/zehua-jiang-4168a11b8" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/jzh_000" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">Feel free to contact me via email or any of the social media platforms. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo" style="background-color: white;"> <div class="container mt-0" style="color: black"> © Copyright 2024 Zehua Jiang. Last update: Jan 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>